{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syntax to download data through terminal: rsync -aP kkulbay@student-shell.sys.kth.se:/afs/kth.se/misc/csc/dept/tmh/corpora/tidigits/disc_4.2.1/tidigits/test/ ~/Desktop/KTH/DT2119_Speech_and_Speaker_Recognition/dt2119/DT2119_Speech/LAB3/tidigits/test\n",
    "\n",
    "import numpy as np\n",
    "import lab3_toolsSPYDER as tools\n",
    "import lab3_proto as proto\n",
    "import lab1_proto as proto1\n",
    "import lab1_tools as tools1\n",
    "import lab2_proto as proto2\n",
    "import lab2_tools as tools2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Target Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneHMMs = np.load('lab2_models_all.npz',allow_pickle=True)['phoneHMMs'].item()\n",
    "phones = sorted(phoneHMMs.keys())\n",
    "nstates = {phone: phoneHMMs[phone]['means'].shape[0] for phone in phones}\n",
    "# stateList = [ph + '_' + str(id) for ph in phones for id in range(nstates[ph])]\n",
    "\n",
    "# np.save(\"stateList.npy\",stateList)\n",
    "\n",
    "#loading genereated list from above \n",
    "stateList = np.load(\"stateList.npy\", allow_pickle=True).tolist()\n",
    "# print(stateList)\n",
    "# print(phoneHMMs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Forced Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#lmfccEXAMPLE = np.load(\"lmfccEXAMPLE.npy\", allow_pickle=True)\n",
    "\n",
    "filename = 'z43a.wav'\n",
    "samples, samplingrate = tools.loadAudio(filename)\n",
    "\n",
    "lmfccEXAMPLE = proto1.mfcc(samples,samplingrate=samplingrate)\n",
    "\n",
    "\n",
    "# plt.pcolormesh(lmfccEXAMPLE)\n",
    "# plt.title(\"MFCCs test\")\n",
    "# plt.show()\n",
    "\n",
    "wordTrans = list(tools.path2info(filename)[2])\n",
    "assert wordTrans == ['z', '4', '3']\n",
    "#-------\n",
    "prondict = {} \n",
    "prondict['o'] = ['ow']\n",
    "prondict['z'] = ['z', 'iy', 'r', 'ow']\n",
    "prondict['1'] = ['w', 'ah', 'n']\n",
    "prondict['2'] = ['t', 'uw']\n",
    "prondict['3'] = ['th', 'r', 'iy']\n",
    "prondict['4'] = ['f', 'ao', 'r']\n",
    "prondict['5'] = ['f', 'ay', 'v']\n",
    "prondict['6'] = ['s', 'ih', 'k', 's']\n",
    "prondict['7'] = ['s', 'eh', 'v', 'ah', 'n']\n",
    "prondict['8'] = ['ey', 't']\n",
    "prondict['9'] = ['n', 'ay', 'n']\n",
    "\n",
    "phoneTrans = proto.words2phones(wordTrans, prondict)\n",
    "assert phoneTrans == ['sil', 'z', 'iy', 'r', 'ow', 'sp', 'f', 'ao', 'r', 'sp', 'th', 'r', 'iy', 'sp', 'sil']\n",
    "#---------\n",
    "utteranceHMM = proto2.concatHMMs(phoneHMMs, phoneTrans)\n",
    "stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans\n",
    "                  for stateid in range(nstates[phone])]\n",
    "# print(stateTrans)\n",
    "# print(stateList)\n",
    "# print(utteranceHMM.keys())\n",
    "# utteranceHMM[\"name\"]\n",
    "\n",
    "#-----\n",
    "lab3example = np.load(\"lab3_example.npz\", allow_pickle=True)\n",
    "\n",
    "#print(utteranceHMM)\n",
    "#print(lab3example[\"example\"])#.f.filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q9/fn0bq0g17g1_dkmkvbvcxll00000gn/T/ipykernel_26829/720878886.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  vloglik, vpath = proto2.viterbi(obsloglik,np.log(utteranceHMM[\"startprob\"]),np.log(utteranceHMM[\"transmat\"][:-1,:-1]))\n"
     ]
    }
   ],
   "source": [
    "obsloglik = tools2.log_multivariate_normal_density_diag(lmfccEXAMPLE,utteranceHMM[\"means\"],utteranceHMM[\"covars\"])\n",
    "vloglik, vpath = proto2.viterbi(obsloglik,np.log(utteranceHMM[\"startprob\"]),np.log(utteranceHMM[\"transmat\"][:-1,:-1]))\n",
    "\n",
    "# print(vpath)\n",
    "# print(len(vpath),len(stateTrans))\n",
    "viterbiStateTrans = []\n",
    "for i,stateID in enumerate(vpath):\n",
    "    viterbiStateTrans.append(stateTrans[stateID])\n",
    "\n",
    "CTRLviterbiStateTrans = ['sil_0', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_1', 'sil_2', 'z_0', 'z_0', 'z_0', 'z_0', 'z_1', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'z_2', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_1', 'iy_2', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_1', 'r_2', 'ow_0', 'ow_1', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'ow_2', 'f_0', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_1', 'f_2', 'ao_0', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_1', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'ao_2', 'r_0', 'r_0', 'r_0', 'r_1', 'r_2', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_0', 'th_1', 'th_1', 'th_1', 'th_2', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_0', 'r_1', 'r_2', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_0', 'iy_1', 'iy_1', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'iy_2', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_0', 'sil_1', 'sil_2']\n",
    "\n",
    "assert CTRLviterbiStateTrans == viterbiStateTrans # This assertion will be incorrect since the loaded example is based on double liftering, main data is not\n",
    "#tools.frames2trans(viterbiStateTrans, outfilename='z43a.lab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tidigits/train/man/ff/o3oo5a.wav\n"
     ]
    }
   ],
   "source": [
    "# traindata = proto.extractDATASET(\"tidigits/train\")\n",
    "# testdata = proto.extractDATASET(\"tidigits/test\")\n",
    "\n",
    "# np.save(\"traindata.npy\",traindata)\n",
    "# np.save(\"testdata.npy\",testdata)\n",
    "\n",
    "traindata = np.load(\"traindata.npy\", allow_pickle=True)\n",
    "testdata = np.load(\"testdata.npy\", allow_pickle=True)\n",
    "\n",
    "# z43aINDEX = None\n",
    "# for i,datapt in enumerate(traindata):\n",
    "#     if datapt[\"filename\"] == \"tidigits/train/man/nw/z43a.wav\":\n",
    "#         z43aINDEX = i\n",
    "\n",
    "z43aINDEX = 3374\n",
    "assert proto._stateIDs2stateNames(traindata[z43aINDEX][\"targets\"],stateList) == CTRLviterbiStateTrans\n",
    "print(traindata[4000][\"filename\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tidigits/train/man/ff/o3oo5a.wav\n",
      "Nspeakers: 112 Nmen: 4235 Nwomen: 4388\n"
     ]
    }
   ],
   "source": [
    "#head, tail = os.path.split(traindata[4000][\"filename\"])\n",
    "print(traindata[4000][\"filename\"])\n",
    "#print(head, tail)\n",
    "\n",
    "#print(proto._getGenderIdFile(traindata[4000][\"filename\"]))\n",
    "#print(proto._getNspeakerNgender(traindata))\n",
    "\n",
    "Nspeakers, Nmen, Nwomen = proto._getNspeakerNgender(traindata)\n",
    "print(\"Nspeakers:\",Nspeakers, \"Nmen:\",Nmen, \"Nwomen:\",Nwomen )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, we seem to have a 50/50 distribution of men/women. So if we take 10% and 90% of each gender pool, we should still have the same distribution in each subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NspeakersMen: 55 NspeakersWomen: 57\n"
     ]
    }
   ],
   "source": [
    "traindataMen = proto.getSubset(traindata,\"man\")\n",
    "traindataWomen = proto.getSubset(traindata,\"woman\")\n",
    "\n",
    "NspeakersMen= proto._getNspeakerNgender(traindataMen)[0]\n",
    "NspeakersWomen= proto._getNspeakerNgender(traindataWomen)[0]\n",
    "\n",
    "print(\"NspeakersMen:\",NspeakersMen, \"NspeakersWomen:\",NspeakersWomen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we now do is that we seperate each gender subset into dictionaries where each key in the dictionary is a speaker ID. This key holds arrays with datapoints only belonging to that speaker. Since we want a 10% subset we calculate how many datapts are needed from each gender. Then these datapts are taken to that approximate value from these unique speakers. Meaning that whatever datapts are remaining only belong to speakers not in the 10% susbet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the 10% subset we need about 423 men samples and  438 women samples\n"
     ]
    }
   ],
   "source": [
    "# traindataMen90, traindataMen10 = proto.splitDatasetUnique(traindataMen,0.9)\n",
    "# traindataWomen90, traindataWomen10 = proto.splitDatasetUnique(traindataWomen,0.9)\n",
    "\n",
    "speakerUniqueSubsetsMen = proto.splitSpeakerSubsets(traindataMen)\n",
    "speakerUniqueSubsetsWomen = proto.splitSpeakerSubsets(traindataWomen)\n",
    "\n",
    "N10Men = int(0.1*len(traindataMen))\n",
    "N10Women = int(0.1*len(traindataWomen))\n",
    "\n",
    "print(\"For the 10% subset we need about\",N10Men, \"men samples and \", N10Women, \"women samples\")\n",
    "\n",
    "# print(speakerUniqueSubsetsMen.keys())\n",
    "# print(len(speakerUniqueSubsetsMen[\"pd\"])+len(speakerUniqueSubsetsMen[\"sj\"])+len(speakerUniqueSubsetsMen[\"pb\"])+len(speakerUniqueSubsetsMen[\"dn\"])+len(speakerUniqueSubsetsMen[\"kd\"])+len(speakerUniqueSubsetsMen[\"nr\"]))\n",
    "# print(speakerUniqueSubsetsWomen.keys())\n",
    "# print(len(speakerUniqueSubsetsWomen[\"pm\"])+len(speakerUniqueSubsetsWomen[\"sp\"])+len(speakerUniqueSubsetsWomen[\"pk\"])+len(speakerUniqueSubsetsWomen[\"pe\"])+len(speakerUniqueSubsetsWomen[\"pp\"])+len(speakerUniqueSubsetsWomen[\"ms\"]))\n",
    "\n",
    "speakerListMen10 = [\"pd\",\"sj\",\"pb\",\"dn\",\"kd\",\"nr\"]\n",
    "speakerListWomen10 = [\"pm\",\"sp\",\"pk\",\"pe\",\"pp\",\"ms\"]\n",
    "\n",
    "traindataMen90 = []\n",
    "traindataMen10 = []\n",
    "\n",
    "for datapt in traindataMen:\n",
    "    filename = datapt[\"filename\"]\n",
    "    speakerID = proto._getGenderIdFile(filename)[1]\n",
    "    if speakerID in speakerListMen10:\n",
    "        traindataMen10.append(datapt)\n",
    "    else:\n",
    "        traindataMen90.append(datapt)\n",
    "\n",
    "traindataWomen90 = []\n",
    "traindataWomen10 = []\n",
    "\n",
    "for datapt in traindataWomen:\n",
    "    filename = datapt[\"filename\"]\n",
    "    speakerID = proto._getGenderIdFile(filename)[1]\n",
    "    if speakerID in speakerListWomen10:\n",
    "        traindataWomen10.append(datapt)\n",
    "    else:\n",
    "        traindataWomen90.append(datapt)\n",
    "\n",
    "# print(len(traindataMen90), len(traindataMen10))\n",
    "# print(len(traindataWomen90), len(traindataWomen10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now combine the seperate gender subsets into two subsets of 90/10 division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ntraindata90: 7699 Ntraindata10: 924\n",
      "Ntraindata: 8623\n"
     ]
    }
   ],
   "source": [
    "traindata90 = traindataMen90 + traindataWomen90\n",
    "traindata10 = traindataMen10 + traindataWomen10\n",
    "\n",
    "print(\"Ntraindata90:\",len(traindata90),\"Ntraindata10:\",len(traindata10))\n",
    "print(\"Ntraindata:\",len(traindata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 Acoustic Context (Dynamic Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 13) (127, 91)\n"
     ]
    }
   ],
   "source": [
    "M = traindata90[3][\"lmfcc\"]\n",
    "Mstack = proto.stackMatrix(M)\n",
    "\n",
    "print(M.shape,Mstack.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boundary cases were simply handled with zero vectors for the feature vectors, since they're not so importaant as each utterance starts and ends with silence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proto.stackDataset(traindata90)\n",
    "# proto.stackDataset(traindata10)\n",
    "# proto.stackDataset(testdata)\n",
    "\n",
    "# np.save(\"traindata90Stacked.npy\",traindata90)\n",
    "# np.save(\"traindata10Stacked.npy\",traindata10)\n",
    "# np.save(\"testdataStacked.npy\",testdata)\n",
    "\n",
    "# traindata90 = np.load(\"traindata90Stacked.npy\", allow_pickle=True)\n",
    "# traindata10 = np.load(\"traindata10Stacked.npy\", allow_pickle=True)\n",
    "# testdata = np.load(\"testdataStacked.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6 Feature Standardisation $\\color{red}{!!!}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about the implications of these different strategies. In the third case, what will happen with the very short utterances in the files containing isolated digits? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = traindata90[3][\"lmfcc\"]\n",
    "# scaler = StandardScaler().fit(data)\n",
    "# dataScaled = scaler.transform(data)\n",
    "# print(dataScaled.mean(axis=0))\n",
    "# print(dataScaled.std(axis=0))\n",
    "\n",
    "# proto.standardiseEachUtterance(traindata90)\n",
    "# proto.standardiseEachUtterance(traindata10)\n",
    "# proto.standardiseEachUtterance(testdata)\n",
    "\n",
    "# print(\"on traindata90\")\n",
    "# np.save(\"traindata90Stand.npy\",traindata90)\n",
    "# print(\"on traindata10\")\n",
    "# np.save(\"traindata10Stand.npy\",traindata10)\n",
    "# print(\"on test\")\n",
    "# np.save(\"testdataStand.npy\",testdata)\n",
    "\n",
    "#traindata90 = np.load(\"traindata90Stand.npy\", allow_pickle=True)\n",
    "# traindata10 = np.load(\"traindata10Stand.npy\", allow_pickle=True)\n",
    "#testdata = np.load(\"testdataStand.npy\", allow_pickle=True)\n",
    "\n",
    "# print(traindata90[5][\"lmfcc\"].mean(axis=0),traindata90[5][\"lmfcc\"].std(axis=0))\n",
    "# print(traindata10[34][\"lmfcc\"].mean(axis=0),traindata10[34][\"lmfcc\"].std(axis=0))\n",
    "# print(testdata[2000][\"lmfcc\"].mean(axis=0),testdata[2000][\"lmfcc\"].std(axis=0))\n",
    "# print(\"OK, means are approx 0 and variance is 1 for each utterance\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347549, 13) (1347549, 40) (1347549, 91) (1347549, 280) (1347549,)\n",
      "(159843, 13) (159843, 40) (159843, 91) (159843, 280) (159843,)\n",
      "(1527014, 13) (1527014, 40) (1527014, 91) (1527014, 280) (1527014,)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#lmfcc_train_x,mspec_train_x,dlmfcc_train_x,dmspec_train_x,train_y = proto.flattenData(traindata90)\n",
    "#np.savez(\"flatDataTrain.npz\", lmfcc_train_x=lmfcc_train_x,mspec_train_x=mspec_train_x,dlmfcc_train_x=dlmfcc_train_x,dmspec_train_x=dmspec_train_x,train_y=train_y)\n",
    "#lmfcc_val_x,mspec_val_x,dlmfcc_val_x,dmspec_val_x,val_y = proto.flattenData(traindata10)\n",
    "#lmfcc_test_x,mspec_test_x,dlmfcc_test_x,dmspec_test_x,test_y = proto.flattenData(testdata)\n",
    "\n",
    "#np.savez(\"flatDataVal.npz\", lmfcc_val_x=lmfcc_val_x,mspec_val_x=mspec_val_x,dlmfcc_val_x=dlmfcc_val_x,dmspec_val_x=dmspec_val_x,val_y=val_y)\n",
    "#np.savez(\"flatDataTest.npz\", lmfcc_test_x=lmfcc_test_x,mspec_test_x=mspec_test_x,dlmfcc_test_x=dlmfcc_test_x,dmspec_test_x=dmspec_test_x,test_y=test_y)\n",
    "\n",
    "#----\n",
    "trainFile = np.load(\"flatDataTrain.npz\")\n",
    "lmfcc_train_x=trainFile[\"lmfcc_train_x\"]\n",
    "mspec_train_x=trainFile[\"mspec_train_x\"]\n",
    "dlmfcc_train_x=trainFile[\"dlmfcc_train_x\"]\n",
    "dmspec_train_x=trainFile[\"dmspec_train_x\"]\n",
    "train_y=trainFile[\"train_y\"]\n",
    "print(lmfcc_train_x.shape,mspec_train_x.shape,dlmfcc_train_x.shape,dmspec_train_x.shape,train_y.shape)\n",
    "#----\n",
    "valFile = np.load(\"flatDataVal.npz\")\n",
    "lmfcc_val_x=valFile[\"lmfcc_val_x\"]\n",
    "mspec_val_x=valFile[\"mspec_val_x\"]\n",
    "dlmfcc_val_x=valFile[\"dlmfcc_val_x\"]\n",
    "dmspec_val_x=valFile[\"dmspec_val_x\"]\n",
    "val_y=valFile[\"val_y\"]\n",
    "print(lmfcc_val_x.shape,mspec_val_x.shape,dlmfcc_val_x.shape,dmspec_val_x.shape,val_y.shape)\n",
    "#----\n",
    "testFile = np.load(\"flatDataTest.npz\")\n",
    "lmfcc_test_x=testFile[\"lmfcc_test_x\"]\n",
    "mspec_test_x=testFile[\"mspec_test_x\"]\n",
    "dlmfcc_test_x=testFile[\"dlmfcc_test_x\"]\n",
    "dmspec_test_x=testFile[\"dmspec_test_x\"]\n",
    "test_y=testFile[\"test_y\"]\n",
    "print(lmfcc_test_x.shape,mspec_test_x.shape,dlmfcc_test_x.shape,dmspec_test_x.shape,test_y.shape)\n",
    "\n",
    "Nstring = 0\n",
    "for i,el in enumerate(train_y):\n",
    "    try: \n",
    "        int(el)\n",
    "    except ValueError:\n",
    "        Nstring += 1\n",
    "        print(el)\n",
    "        train_y[i] = stateList.index(el)\n",
    "print(Nstring)\n",
    "\n",
    "#np.savez(\"flatDataTrain.npz\", lmfcc_train_x=lmfcc_train_x,mspec_train_x=mspec_train_x,dlmfcc_train_x=dlmfcc_train_x,dmspec_train_x=dmspec_train_x,train_y=train_y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fec642dd07d6379f9b6a5394665ddfa18c171d75eab9dccee14f3e20cb5996de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
