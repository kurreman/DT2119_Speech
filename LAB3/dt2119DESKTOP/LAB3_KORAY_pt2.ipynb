{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a second notebook due to environment issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lab3_tools as tools\n",
    "import lab3_proto as proto\n",
    "import lab1_proto as proto1\n",
    "import lab1_tools as tools1\n",
    "import lab2_proto as proto2\n",
    "import lab2_tools as tools2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#from tensorflow.keras.utils import np_utils\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateList = np.load(\"stateList.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6 continuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = len(stateList)\n",
    "#----\n",
    "trainFile = np.load(\"flatDataTrain.npz\")\n",
    "lmfcc_train_x=trainFile[\"lmfcc_train_x\"].astype('float32')\n",
    "mspec_train_x=trainFile[\"mspec_train_x\"].astype('float32')\n",
    "dlmfcc_train_x=trainFile[\"dlmfcc_train_x\"].astype('float32')\n",
    "dmspec_train_x=trainFile[\"dmspec_train_x\"].astype('float32')\n",
    "train_y=np_utils.to_categorical(trainFile[\"train_y\"],output_dim)\n",
    "#print(lmfcc_train_x.shape,mspec_train_x.shape,dlmfcc_train_x.shape,dmspec_train_x.shape,train_y.shape) #| Shapes checked and OK\n",
    "#----\n",
    "valFile = np.load(\"flatDataVal.npz\")\n",
    "lmfcc_val_x=valFile[\"lmfcc_val_x\"].astype('float32')\n",
    "mspec_val_x=valFile[\"mspec_val_x\"].astype('float32')\n",
    "dlmfcc_val_x=valFile[\"dlmfcc_val_x\"].astype('float32')\n",
    "dmspec_val_x=valFile[\"dmspec_val_x\"].astype('float32')\n",
    "val_y=np_utils.to_categorical(valFile[\"val_y\"],output_dim)\n",
    "#print(lmfcc_val_x.shape,mspec_val_x.shape,dlmfcc_val_x.shape,dmspec_val_x.shape,val_y.shape)\n",
    "#----\n",
    "testFile = np.load(\"flatDataTest.npz\")\n",
    "lmfcc_test_x=testFile[\"lmfcc_test_x\"].astype('float32')\n",
    "mspec_test_x=testFile[\"mspec_test_x\"].astype('float32')\n",
    "dlmfcc_test_x=testFile[\"dlmfcc_test_x\"].astype('float32')\n",
    "dmspec_test_x=testFile[\"dmspec_test_x\"].astype('float32')\n",
    "test_y=np_utils.to_categorical(testFile[\"test_y\"],output_dim)\n",
    "#print(lmfcc_test_x.shape,mspec_test_x.shape,dlmfcc_test_x.shape,dmspec_test_x.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Phoneme Recognition with Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 80)                1120      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 61)                4941      \n",
      "=================================================================\n",
      "Total params: 6,061\n",
      "Trainable params: 6,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "features = lmfcc_train_x\n",
    "labels = train_y\n",
    "features_test = lmfcc_test_x\n",
    "labels_test = test_y\n",
    "feature_dim = features.shape[1]\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(80,activation=tf.nn.relu,input_shape=(feature_dim,))) #choose ReLu since it's faster to compute compared to Sigmoid\n",
    "model.add(tf.keras.layers.Dense(output_dim,activation=tf.nn.softmax)) #softmax distributes probabilitites across our states\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "            optimizer=\"sgd\",\n",
    "            metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5264/5264 [==============================] - 5s 813us/step - loss: 2.5109 - accuracy: 0.3621\n",
      "Epoch 2/20\n",
      "5264/5264 [==============================] - 5s 867us/step - loss: 1.8401 - accuracy: 0.4691\n",
      "Epoch 3/20\n",
      "5264/5264 [==============================] - 5s 880us/step - loss: 1.7456 - accuracy: 0.4835\n",
      "Epoch 4/20\n",
      "5264/5264 [==============================] - 5s 878us/step - loss: 1.7078 - accuracy: 0.4904\n",
      "Epoch 5/20\n",
      "5264/5264 [==============================] - 5s 873us/step - loss: 1.6843 - accuracy: 0.4952\n",
      "Epoch 6/20\n",
      "5264/5264 [==============================] - 5s 887us/step - loss: 1.6664 - accuracy: 0.4990\n",
      "Epoch 7/20\n",
      "5264/5264 [==============================] - 5s 885us/step - loss: 1.6515 - accuracy: 0.5022\n",
      "Epoch 8/20\n",
      "5264/5264 [==============================] - 5s 892us/step - loss: 1.6385 - accuracy: 0.5049\n",
      "Epoch 9/20\n",
      "5264/5264 [==============================] - 5s 888us/step - loss: 1.6271 - accuracy: 0.5075\n",
      "Epoch 10/20\n",
      "5264/5264 [==============================] - 5s 894us/step - loss: 1.6169 - accuracy: 0.5098\n",
      "Epoch 11/20\n",
      "5264/5264 [==============================] - 5s 891us/step - loss: 1.6077 - accuracy: 0.5117\n",
      "Epoch 12/20\n",
      "5264/5264 [==============================] - 5s 888us/step - loss: 1.5992 - accuracy: 0.5137\n",
      "Epoch 13/20\n",
      "5264/5264 [==============================] - 5s 884us/step - loss: 1.5916 - accuracy: 0.5155\n",
      "Epoch 14/20\n",
      "5264/5264 [==============================] - 5s 890us/step - loss: 1.5845 - accuracy: 0.5172\n",
      "Epoch 15/20\n",
      "5264/5264 [==============================] - 5s 895us/step - loss: 1.5781 - accuracy: 0.5186\n",
      "Epoch 16/20\n",
      "5264/5264 [==============================] - 5s 913us/step - loss: 1.5721 - accuracy: 0.5199\n",
      "Epoch 17/20\n",
      "5264/5264 [==============================] - 5s 894us/step - loss: 1.5667 - accuracy: 0.5213\n",
      "Epoch 18/20\n",
      "5264/5264 [==============================] - 5s 905us/step - loss: 1.5616 - accuracy: 0.5225\n",
      "Epoch 19/20\n",
      "5264/5264 [==============================] - 5s 889us/step - loss: 1.5570 - accuracy: 0.5235\n",
      "Epoch 20/20\n",
      "5264/5264 [==============================] - 5s 890us/step - loss: 1.5527 - accuracy: 0.5244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ed0854d700>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20 #Goes through data set EPOCHS number of times \n",
    "BATCH_SIZE = 256 #Each training step model will see BATCH_SIZE number of examples to guide and adjust parameters\n",
    "\n",
    "model.fit(features,labels,epochs=EPOCHS,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose of validation data? \n",
    "\n",
    "- Training data: Used to created weights of neural network\n",
    "- Validation data: Used to compare different neural networks and choose the one that gives best result\n",
    "- Test data: Simply used to test performance of the trained and chosen neural network. If not good results, start over. \n",
    "\n",
    "If you use the training and validation data as the same, the choice of neural network can be biased. Which means that the neural network was chosen as better just for that data. Real world data mighjt not have that connection to the neural network and might therefore not perform well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47720/47720 [==============================] - 25s 526us/step - loss: 1.5896 - accuracy: 0.5108\n",
      "test_acc: 0.5108054280281067\n",
      "test_loss: 1.5896146297454834\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(features_test,labels_test)\n",
    "print(\"test_acc:\",test_acc) #Can increase with more epochs and more sofisticated model\n",
    "print(\"test_loss:\",test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Possible questions\n",
    "\n",
    "- what is the influence of feature kind and size of input context window?\n",
    "    - The input kind is important since that reveals the amount of \"hidden data\". Ex. the lmfcc has been stripped of some information compared to the mspecs. This can later be interpred by the hidden layers. \n",
    "    -   input context window $\\color{red}{!!!}$\n",
    "- what is the purpose of normalising (standardising) the input feature vectors depending on\n",
    "the activation functions in the network?\n",
    "    - Because otherwise some values that shouldn't activate the activation function will do so and vice versa. When normalising all values, one ensures that all data is represented in relation to each other.\n",
    "    - Looking at what happens when one only normalises for each utterance, some parts of an utterance might trigger the activation function even though it wouldn't have if one normalised all utterances in relation to each other. This is why shorter utterances might be over represented when one only normalises for each utternace in isolation.\n",
    "- what is the influence of the number of units per layer and the number of layers?\n",
    "    - answer\n",
    "- what is the influence of the activation function (when you try other activation functions\n",
    "than ReLU, you do not need to reach convergence in case you do not have enough time)\n",
    "    - answer\n",
    "- what is the influence of the learning rate/learning rate strategy?\n",
    "    - answer\n",
    "- how stable are the posteriograms from the network in time?\n",
    "    - answer\n",
    "- how do the errors distribute depending on phonetic class?\n",
    "    - answer"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c56dde32312b51f3125b3da835da250fcf310d1475bfad666419fd8986aabd3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
